// api/analyze-apple-podcast.js
// Apple URL ‚Üí metadata ‚Üí stream remote MP3 ‚Üí Vercel Blob ‚Üí (auto-transcode if large) ‚Üí Groq Whisper ‚Üí TROOP

import { setCorsHeaders } from '../lib/cors.js';
import FormData from 'form-data';
import { put } from '@vercel/blob';
import ffmpegPath from 'ffmpeg-static';
import { spawn } from 'child_process';

const APP_CONFIG = {
  METADATA_URL: 'https://podcast-api-amber.vercel.app/api/transcribe',
  GROQ: {
    API_URL: 'https://api.groq.com/openai/v1/audio/transcriptions',
    MODEL: 'whisper-large-v3-turbo',
    RESPONSE_FORMAT: 'text',
  },
  OPENAI: {
    CHAT_URL: 'https://api.openai.com/v1/chat/completions',
    ANALYSIS_MODEL: 'gpt-4o-mini',
  },
  HARD_SIZE_LIMIT_BYTES: 1024 * 1024 * 300, // 300MB
  GROQ_SOFT_LIMIT_BYTES: 24 * 1024 * 1024, // if above this, transcode
  HTTP_TIMEOUT_MS: 45_000,
  RETRIES: 2,
};

export default async function handler(req, res) {
  setCorsHeaders(res, req.headers.origin);
  if (req.method === 'OPTIONS') return res.status(200).end();
  if (req.method !== 'POST') return res.status(405).json({ error: 'Method not allowed' });

  const start = Date.now();
  const debug = [];

  try {
    const { appleUrl, title } = await readJsonBody(req);
    if (!appleUrl) return res.status(400).json({ error: 'Apple Podcast URL is required' });

    debug.push(`üöÄ Start Apple URL flow: ${appleUrl}`);

    // 1) Metadata
    const meta = await getEpisodeMetadata(appleUrl, debug);
    const episodeTitle = meta.title || title || 'Episode';
    const podcastTitle = meta.podcast_title || meta.podcastTitle || 'Podcast';
    const audioUrl = pickAudioUrl(meta);
    if (!audioUrl) {
      return res.status(400).json({ error: 'No audio URL found in metadata (enclosure missing).', debug });
    }
    debug.push(`üéâ Metadata extracted: "${episodeTitle}"`);
    debug.push(`üéµ MP3: ${String(audioUrl).slice(0, 180)}‚Ä¶`);

    // 2) HEAD size/type
    const { contentLength, contentType } = await headInfo(audioUrl);
    if (contentLength && contentLength > APP_CONFIG.HARD_SIZE_LIMIT_BYTES) {
      return res.status(413).json({
        error: `Audio too large (${Math.round(contentLength / 1024 / 1024)}MB). Use MP3 upload path.`,
        debug,
      });
    }

    // 3) Stream Apple MP3 ‚Üí Blob
    debug.push('‚òÅÔ∏è Uploading remote MP3 to Vercel Blob (stream)‚Ä¶');
    const fileName = makeSafeFileName(`${episodeTitle}-${Date.now()}.mp3`);
    const blobPut = await uploadRemoteToBlob(audioUrl, fileName, contentType || 'audio/mpeg');
    const blobUrl = blobPut.url;
    debug.push(`‚úÖ Blob stored: ${blobUrl}`);

    // 4) Decide: transcode if large
    const blobHead = await headInfo(blobUrl);
    const needsTranscode = (blobHead.contentLength || 0) > APP_CONFIG.GROQ_SOFT_LIMIT_BYTES;

    let audioBuffer;
    if (!needsTranscode) {
      debug.push(`üì¶ Blob size OK (${Math.round((blobHead.contentLength || 0) / (1024*1024))}MB) ‚Äî skipping transcode`);
      audioBuffer = await downloadToBuffer(blobUrl);
    } else {
      debug.push(`ü™Ñ Transcoding to ~32kbps mono MP3 to satisfy Groq size limits‚Ä¶`);
      audioBuffer = await transcodeBlobToLowBitrate(blobUrl, debug);
      debug.push(`‚úÖ Transcode complete, size ~${Math.round(audioBuffer.length / (1024*1024))}MB`);
    }

    // 5) Transcribe with Groq
    debug.push('‚ö° Transcribing via Groq‚Ä¶');
    const { transcript, metrics } = await transcribeBufferWithGroq(audioBuffer, `${episodeTitle}.mp3`);
    debug.push(`‚úÖ Transcription complete, chars: ${transcript.length}`);

    // 6) TROOP analysis
    debug.push('üß† Running Enhanced TROOP analysis‚Ä¶');
    const analysis = await analyzeWithEnhancedTROOP(transcript, episodeTitle, podcastTitle);
    debug.push('‚úÖ Enhanced TROOP analysis completed successfully');

    const processing_time_ms = Date.now() - start;
    return res.status(200).json({
      success: true,
      source: 'Apple URL ‚Üí Blob ‚Üí (auto-transcode if large) ‚Üí Groq ‚Üí TROOP',
      metadata: {
        title: episodeTitle,
        duration: meta.duration || metrics.durationSeconds,
        podcastTitle,
        originalUrl: appleUrl,
        searchTerm: meta.search_term,
        listenNotesId: meta.listennotes_id,
        audioUrl,
        blobUrl,
        transcriptionSource: metrics.source,
        audio_metrics: metrics,
        processed_at: new Date().toISOString(),
        processing_time_ms,
        api_version: '4.4-apple-blob-transcode-troop',
      },
      transcript,
      description: meta.description,
      keywords: meta.keywords || [],
      analysis,
      debug,
    });
  } catch (err) {
    const processing_time_ms = Date.now() - start;
    return res.status(500).json({
      error: 'Analysis failed',
      details: String(err?.message || err),
      processing_time_ms,
    });
  }
}

/* ---------------------------
   Net helpers
----------------------------*/

async function readJsonBody(req) {
  const chunks = [];
  for await (const c of req) chunks.push(c);
  const raw = Buffer.concat(chunks).toString('utf8') || '{}';
  return JSON.parse(raw);
}

function makeSafeFileName(name) {
  return name.replace(/[^\w.\-]+/g, '_').slice(0, 120);
}

async function fetchWithRetries(url, opts = {}, retries = APP_CONFIG.RETRIES) {
  const { default: fetch } = await import('node-fetch');
  const controller = new AbortController();
  const t = setTimeout(() => controller.abort(), APP_CONFIG.HTTP_TIMEOUT_MS);
  try {
    const resp = await fetch(url, { ...opts, signal: controller.signal });
    clearTimeout(t);
    if (!resp.ok && retries > 0 && resp.status >= 500) {
      return fetchWithRetries(url, opts, retries - 1);
    }
    return resp;
  } catch (e) {
    clearTimeout(t);
    if (retries > 0) return fetchWithRetries(url, opts, retries - 1);
    throw e;
  }
}

async function headInfo(url) {
  try {
    const r = await fetchWithRetries(url, { method: 'HEAD' });
    if (!r.ok) return { contentLength: 0, contentType: '' };
    return {
      contentLength: Number(r.headers.get('content-length') || 0),
      contentType: r.headers.get('content-type') || '',
    };
  } catch {
    return { contentLength: 0, contentType: '' };
  }
}

async function uploadRemoteToBlob(remoteUrl, fileName, contentTypeGuess) {
  const res = await fetchWithRetries(remoteUrl, { method: 'GET' });
  if (!res.ok || !res.body) {
    const msg = await safeReadText(res);
    throw new Error(`Remote MP3 download failed: ${res.status} ${res.statusText} ${msg ? `| ${msg}` : ''}`);
  }
  const ct = res.headers.get('content-type') || contentTypeGuess || 'audio/mpeg';
  return await put(fileName, res.body, { access: 'public', contentType: ct });
}

async function safeReadText(resp) {
  try { return await resp.text(); } catch { return ''; }
}

async function downloadToBuffer(url) {
  const { default: fetch } = await import('node-fetch');
  const r = await fetch(url);
  if (!r.ok) {
    const txt = await safeReadText(r);
    throw new Error(`Blob read failed: ${r.status} ${r.statusText} ${txt ? `| ${txt}` : ''}`);
  }
  const ab = await r.arrayBuffer();
  return Buffer.from(ab);
}

/* ---------------------------
   Transcode (ffmpeg-static)
----------------------------*/

async function transcodeBlobToLowBitrate(blobUrl, debug) {
  const { default: fetch } = await import('node-fetch');

  if (!ffmpegPath) {
    throw new Error('ffmpeg not found (ffmpeg-static). Run: npm i ffmpeg-static');
  }

  const resp = await fetch(blobUrl);
  if (!resp.ok || !resp.body) {
    const txt = await safeReadText(resp);
    throw new Error(`Failed to stream Blob for transcode: ${resp.status} ${resp.statusText} ${txt ? `| ${txt}` : ''}`);
  }

  // ffmpeg args: read from stdin, output mp3, 32k mono, low sample rate
  const args = [
    '-hide_banner',
    '-loglevel', 'error',
    '-i', 'pipe:0',
    '-ac', '1',
    '-ar', '16000',
    '-b:a', '32k',
    '-f', 'mp3',
    'pipe:1'
  ];

  const ff = spawn(ffmpegPath, args, { stdio: ['pipe', 'pipe', 'pipe'] });

  // Pipe input
  resp.body.on('error', (e) => ff.stdin.destroy(e));
  resp.body.pipe(ff.stdin);

  // Collect output
  const chunks = [];
  const errors = [];
  ff.stdout.on('data', (d) => chunks.push(d));
  ff.stderr.on('data', (d) => errors.push(d));

  await new Promise((resolve, reject) => {
    ff.on('close', (code) => {
      if (code === 0) return resolve();
      reject(new Error(`ffmpeg failed (code ${code}): ${Buffer.concat(errors).toString()}`));
    });
    ff.on('error', reject);
  });

  const out = Buffer.concat(chunks);
  if (out.length === 0) {
    throw new Error(`ffmpeg produced empty output: ${Buffer.concat(errors).toString()}`);
  }
  return out;
}

/* ---------------------------
   Transcribe (Groq)
----------------------------*/

async function transcribeBufferWithGroq(fileBuffer, filename = 'episode.mp3') {
  const groqApiKey = process.env.GROQ_API_KEY;
  if (!groqApiKey) throw new Error('Groq API key not configured');

  const { default: fetch } = await import('node-fetch');

  const form = new FormData();
  form.append('file', fileBuffer, { filename, contentType: 'audio/mpeg' });
  form.append('model', APP_CONFIG.GROQ.MODEL);
  form.append('response_format', APP_CONFIG.GROQ.RESPONSE_FORMAT);

  const groqResp = await fetch(APP_CONFIG.GROQ.API_URL, {
    method: 'POST',
    headers: { Authorization: `Bearer ${groqApiKey}`, ...form.getHeaders() },
    body: form,
  });

  if (!groqResp.ok) {
    const errText = await safeReadText(groqResp);
    throw new Error(`Groq API error: ${groqResp.status} ${groqResp.statusText} ${errText ? `| ${errText}` : ''}`);
  }

  const transcript = await groqResp.text();
  const durationEstimate = transcript.length / 8;
  return {
    transcript,
    metrics: {
      durationSeconds: Math.round(durationEstimate),
      durationMinutes: Math.round(durationEstimate / 60),
      confidence: 'estimated',
      source: 'groq',
    },
  };
}

/* ---------------------------------
   TROOP (unchanged core)
---------------------------------- */

async function analyzeWithEnhancedTROOP(transcript, episodeTitle = '', podcastTitle = '') {
  const openaiApiKey = process.env.OPENAI_API_KEY;
  if (!openaiApiKey) return createFallbackAnalysis(transcript, episodeTitle);

  const baseSystem = [
    'You are Podcast Growth Agent.',
    'Respond with valid JSON only. No markdown, no code fences, no commentary.',
    'Do NOT provide medical advice or health recommendations; focus strictly on marketing, SEO, audience targeting, and community strategy.',
    'Arrays MUST contain exactly 3 items for tweetable_quotes, community_suggestions, and cross_promo_matches.'
  ].join(' ');

  const enhancedTROOPPrompt = `**TASK:** ... (UNCHANGED FROM YOUR LAST WORKING PROMPT) ...`;

  // For brevity here, paste your exact TROOP prompt block from your last working version.
  // (I kept the structure identical; only the ingest/transcode changed.)

  const attempt1 = await callOpenAI(enhancedTROOPPrompt, openaiApiKey, baseSystem);
  if (attempt1.ok) return attempt1.json;

  const attempt2 = await callOpenAI(enhancedTROOPPrompt, openaiApiKey, baseSystem);
  if (attempt2.ok) return attempt2.json;

  const distilled = await distillTranscript(transcript, openaiApiKey, baseSystem);
  const distilledPrompt = enhancedTROOPPrompt.replace(
    /\*\*TRANSCRIPT:\*\*[\s\S]*$/m,
    `**TRANSCRIPT (DISTILLED):**\n${distilled}\n\nRespond ONLY with valid JSON.`
  );
  const attempt3 = await callOpenAI(distilledPrompt, openaiApiKey, baseSystem);
  if (attempt3.ok) return attempt3.json;

  return {
    ...createFallbackAnalysis(transcript, episodeTitle),
    _debug_troop_fail: {
      first_error: attempt1.errorText,
      second_error: attempt2.errorText,
      third_error: attempt3.errorText,
    },
  };
}

async function callOpenAI(prompt, apiKey, baseSystem) {
  const { default: fetch } = await import('node-fetch');
  const resp = await fetch(APP_CONFIG.OPENAI.CHAT_URL, {
    method: 'POST',
    headers: { Authorization: `Bearer ${apiKey}`, 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: APP_CONFIG.OPENAI.ANALYSIS_MODEL,
      response_format: { type: 'json_object' },
      temperature: 0.7,
      max_tokens: 4000,
      messages: [
        { role: 'system', content: baseSystem },
        { role: 'user', content: prompt },
      ],
    }),
  });

  const status = resp.status;
  const raw = await resp.text();

  if (status < 200 || status >= 300) return { ok: false, status, errorText: raw };

  let data;
  try { data = JSON.parse(raw); }
  catch (e) { return { ok: false, status, errorText: `JSON parse error: ${e.message} | raw=${raw.slice(0, 400)}...` }; }

  const content = data.choices?.[0]?.message?.content;
  if (!content) return { ok: false, status, errorText: `No content | raw=${raw.slice(0, 400)}...` };

  try { return { ok: true, json: JSON.parse(content) }; }
  catch {
    const m = content.match(/\{[\s\S]*\}/);
    if (m) { try { return { ok: true, json: JSON.parse(m[0]) }; } catch {} }
    return { ok: false, status, errorText: `Model content not valid JSON: ${content.slice(0, 300)}...` };
  }
}

async function distillTranscript(transcript, apiKey, baseSystem) {
  const distilledPrompt = [
    'Condense the following transcript into JSON with keys:',
    '{ "summary": "...", "key_points": ["..."], "entities": ["..."], "topics": ["..."], "quotes": ["..."] }',
    'Focus ONLY on marketing-relevant themes, audience pain points, quotable lines, and topic clusters.',
    'Avoid medical advice; do not include instructions or sensitive guidance.',
    '',
    transcript.length > 24000 ? transcript.substring(0, 24000) + '\n\n[Truncated for distillation]' : transcript,
  ].join('\n');

  const { default: fetch } = await import('node-fetch');
  const resp = await fetch(APP_CONFIG.OPENAI.CHAT_URL, {
    method: 'POST',
    headers: { Authorization: `Bearer ${apiKey}`, 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: APP_CONFIG.OPENAI.ANALYSIS_MODEL,
      response_format: { type: 'json_object' },
      temperature: 0.5,
      max_tokens: 1200,
      messages: [
        { role: 'system', content: baseSystem },
        { role: 'user', content: distilledPrompt },
      ],
    }),
  });

  const raw = await resp.text();
  try {
    const data = JSON.parse(raw);
    const content = data.choices?.[0]?.message?.content || '{}';
    const json = JSON.parse(content);
    return [
      `SUMMARY: ${json.summary || ''}`,
      `KEY_POINTS: ${(Array.isArray(json.key_points) ? json.key_points : []).join(' | ')}`,
      `ENTITIES: ${(Array.isArray(json.entities) ? json.entities : []).join(', ')}`,
      `TOPICS: ${(Array.isArray(json.topics) ? json.topics : []).join(', ')}`,
      `QUOTES: ${(Array.isArray(json.quotes) ? json.quotes : []).join(' | ')}`,
    ].join('\n');
  } catch {
    return transcript.slice(0, 8000);
  }
}

function createFallbackAnalysis(transcript, episodeTitle) {
  return {
    episode_summary: "Episode successfully transcribed. Enhanced AI analysis temporarily unavailable - using fallback.",
    tweetable_quotes: [
      `üéôÔ∏è New episode: "${episodeTitle}" - packed with insights for growth!`,
      "üìà Every episode is an opportunity to connect with your audience.",
      "üöÄ Consistent content creation is the key to podcast growth.",
    ],
    topics_keywords: ["podcast", "content", "growth", "strategy", "audience"],
    optimized_title: episodeTitle || "Optimize This Episode Title for SEO",
    optimized_description: "Use the episode content to craft an engaging description that drives discovery and engagement.",
    community_suggestions: [
      { name: "Mindfulness Community", platform: "Reddit", url: "https://reddit.com/r/mindfulness", why: "Share mindful practices and wellness insights" },
      { name: "Self Care Support", platform: "Facebook", url: "https://facebook.com/groups/selfcaresupport", why: "Connect with people focused on personal wellness" },
      { name: "Wellness Warriors", platform: "Discord", url: "https://discord.com/invite/wellness", why: "Real-time community for health and wellness discussions" },
    ],
    cross_promo_matches: [
      { podcast_name: "The Wellness Hour", host_name: "Sarah Johnson", contact_info: "@sarahwellness", collaboration_angle: "Practical wellness overlap" },
      { podcast_name: "Mindful Living Daily", host_name: "Mike Chen", contact_info: "mike@mindfulpodcast.com", collaboration_angle: "Mindfulness-focused audience" },
      { podcast_name: "Health & Home", host_name: "Lisa Rodriguez", contact_info: "@healthandhomepod", collaboration_angle: "Healthy living spaces" },
    ],
    trend_piggyback: "Connect to current wellness and mental health awareness trends (#MindfulMonday #SelfCareSunday).",
    social_caption: `üéôÔ∏è New episode live: "${episodeTitle}" ‚Äî dive into insights that matter. #podcast #wellness #mindfulness`,
    next_step: "Create 3 post variants with quotes + hashtags; share in one targeted community today.",
    growth_score: "75/100 - Transcribed successfully; advanced analysis fell back.",
  };
}
